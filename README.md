# modle-for-QQP

需要环境：tensorflow1.4，Python3.6，numpy，random，collections，csv

train.py文件是执行训练命令的脚本文件

model.py文件是模型构造主文件，该文件中编写了一个名为model的类，模型框架结构都在该类中被定义，包括输入变量，loss函数，acc函数，编码器，分类器等结构

function.py文件是自定义函数方法脚本文件，该文件中定义了在model中用到的一些函数方法，这些代码块功能相对独立，供外部引用文件使用，如fully_conacation，Dynamic_LSTM，con2D等

tool.py文件是数据预处理及读取数据文件，其中包括get_data,get_epoch,get_batch,read_file,load_vector,get_char等函数，同样的这个代码块功能相对单一，且相互独立，有些函数需要在网络运行之前预先进行处理，有些则是和网络一起运行，注意区分

config.py文件是用来预先定义超参数，如batch_size，embedding_size等，只能供别的脚本文件调用

使用该工程时，先使用tool.py文件里面的 get_data方法，支持使用相对路径以及绝对路径，建议使用相对路径，将数据集处理成index形式，方便模型直接读取。该代码涉及的步骤包括分词，统计词频，建立词典，将原文本映射成index形式，最后保存index文件。

接下来将train.py文件里的文件读取路径修改成自己的相对工程路径，直接运行train.py文件，网络会开始训练，如若需要读取已保存模型，只需将init_op注释掉，加上读取模型的代码即可继续训练。

该模型加入了char-conv的信息，也就是将每个单词拆解为每个字符，然后为每个字符映射字符向量，一句话就可以映射为一个三维矩阵，利用卷积，将每个单词再卷积为一个向量。

# 1、模型任务

问题对相似度匹配任务算是自然语言处理领域比较热门的一个方向了，通过问题对的相似度计算，来用一个问题的答案去回答另一个问题，是自动问答领域的一个研究方向。
数据集形式是句子对加标签的形式给定，标签为0或者1，前者表示不相似，后者表示相似。通过模型的计算最后给出两个句子的相似概率，经过计算来判定两者相似或者不相似。

# 2、模型结构

先将字符进行卷积，通过字符卷积操作，将输入字符的维度变成和输入词向量一样的维度，然后将字符卷积结果和词向量一起拼接起来，在最后一个维度上拼接，

采用co-dynamic_LSTM结构作为编码器，能够很好的提取两个句子的交互信息和各自的信息。

编码器堆叠了6层的co-dynamic_LSTM，深度编码语义信息。

之后将两个句子交互的信息经过三层全连接结构输出概率分布。

# 3、模型创新点

参考BERT模型微调阶段原理原理，将两个句子用一个特殊字符拼接起来，作为唯一的输入，既保证了两个句子在模型初始就开始交互信息，又使模型能经过两个句子的训练，保证了模型的鲁棒性。

双向LSTM能够将信息从句子一流向句子二，同时又能反向流动，使得两个句子间充分交互。

Self-attention结构能够使句子一和句子二之间进行进一步信息流动，auto-encoder使得模型参数不至于太大，起到压缩语义向量的作用。预测时使用中间特殊字符的语义表示，这部分向量充分经过句子一和句子二的信息融合，具有完整的信息。

# 4、实验效果

准确率86%，F1值89%
